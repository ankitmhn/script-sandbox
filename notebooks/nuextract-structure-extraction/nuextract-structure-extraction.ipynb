{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitmhn/script-sandbox/blob/main/notebooks/nuextract-structure-extraction/nuextract-structure-extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6aa8c52-9bde-41a6-a5f7-4fa93d5c2a6c",
      "metadata": {
        "id": "f6aa8c52-9bde-41a6-a5f7-4fa93d5c2a6c"
      },
      "source": [
        "# Structure Extraction with NuExtract and OpenVINO\n",
        "\n",
        "![image](https://github.com/user-attachments/assets/70dd93cc-da36-4c53-8891-78c0f9a41f20)\n",
        "\n",
        "[NuExtract](https://huggingface.co/numind/NuExtract) model is a text-to-JSON Large Language Model (LLM) that allows to extract arbitrarily complex information from text and turns it into structured data.\n",
        "\n",
        "LLM stands for “Large Language Model” which refers to a type of artificial intelligence model that is designed to understand and generate human-like text based on the input it receives. LLMs are trained on large datasets of text to learn patterns, grammar, and semantic relationships, allowing them to generate coherent and contextually relevant responses. One core capability of Large Language Models (LLMs) is to follow natural language instructions. Instruction-following models are capable of generating text in response to prompts and are often used for tasks like writing assistance, chatbots, and content generation.\n",
        "\n",
        "In this tutorial, we consider how to run a structure extraction text generation pipeline using NuExtract model and OpenVINO. We will use pre-trained models from the [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) library. The [Hugging Face Optimum Intel](https://huggingface.co/docs/optimum/intel/index) library converts the models to OpenVINO™ IR format. To simplify the user experience, we will use [OpenVINO Generate API](https://github.com/openvinotoolkit/openvino.genai) for generation inference pipeline.  \n",
        "\n",
        "The tutorial consists of the following steps:\n",
        "\n",
        "- Install prerequisites\n",
        "- Download and convert the model from a public source using the [OpenVINO integration with Hugging Face Optimum](https://huggingface.co/blog/openvino)\n",
        "- Compress model weights to INT8 and INT4 with [OpenVINO NNCF](https://github.com/openvinotoolkit/nncf)\n",
        "- Create a structure extraction inference pipeline with [Generate API](https://github.com/openvinotoolkit/openvino.genai)\n",
        "- Launch interactive Gradio demo with structure extraction pipeline\n",
        "\n",
        "\n",
        "#### Table of contents:\n",
        "\n",
        "- [Prerequisites](#Prerequisites)\n",
        "- [Select model for inference](#Select-model-for-inference)\n",
        "- [Download and convert model to OpenVINO IR via Optimum Intel CLI](#Download-and-convert-model-to-OpenVINO-IR-via-Optimum-Intel-CLI)\n",
        "- [Compress model weights](#Compress-model-weights)\n",
        "    - [Weights Compression using Optimum Intel CLI](#weights-compression-using-optimum-intel-cli)\n",
        "- [Select device for inference and model variant](#Select-device-for-inference-and-model-variant)\n",
        "- [Create a structure extraction inference pipeline](#Create-a-structure-extraction-inference-pipeline)\n",
        "- [Run interactive structure extraction demo with Gradio](#Run-interactive-structure-extraction-demo-with-Gradio)\n",
        "\n",
        "\n",
        "### Installation Instructions\n",
        "\n",
        "This is a self-contained example that relies solely on its own code.\n",
        "\n",
        "We recommend  running the notebook in a virtual environment. You only need a Jupyter server to start.\n",
        "For details, please refer to [Installation Guide](https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/README.md#-installation-guide).\n",
        "\n",
        "<img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=5b5a4db0-7875-4bfb-bdbd-01698b5b1a77&file=notebooks/nuextract-structure-extraction/nuextract-structure-extraction.ipynb\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "027108c2-1fbe-4be5-9e23-3fc359185a42",
      "metadata": {
        "id": "027108c2-1fbe-4be5-9e23-3fc359185a42"
      },
      "source": [
        "## Prerequisites\n",
        "[back to top ⬆️](#Table-of-contents:)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5d0473c6-3734-422d-a370-2e39d576be0e",
      "metadata": {
        "id": "5d0473c6-3734-422d-a370-2e39d576be0e",
        "outputId": "261ecb2b-3d39-4284-df2d-315251428673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -q \"torch>=2.1\" \"nncf>=2.12\" \"transformers>=4.40.0\" \"accelerate\" \"gradio>=4.19\" \"git+https://github.com/huggingface/optimum-intel.git\" --extra-index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "48ded239",
      "metadata": {
        "id": "48ded239",
        "outputId": "a77a64b4-f0c6-4f6c-e28d-d69c427de64b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM config will be updated\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import shutil\n",
        "\n",
        "if not Path(\"notebook_utils.py\").exists():\n",
        "    r = requests.get(url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py\")\n",
        "    open(\"notebook_utils.py\", \"w\").write(r.text)\n",
        "\n",
        "from notebook_utils import download_file\n",
        "\n",
        "# Fetch llm_config.py\n",
        "llm_config_shared_path = Path(\"../../utils/llm_config.py\")\n",
        "llm_config_dst_path = Path(\"llm_config.py\")\n",
        "\n",
        "if not llm_config_dst_path.exists():\n",
        "    if llm_config_shared_path.exists():\n",
        "        try:\n",
        "            os.symlink(llm_config_shared_path, llm_config_dst_path)\n",
        "        except Exception:\n",
        "            shutil.copy(llm_config_shared_path, llm_config_dst_path)\n",
        "    else:\n",
        "        download_file(url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/llm_config.py\")\n",
        "elif not os.path.islink(llm_config_dst_path):\n",
        "    print(\"LLM config will be updated\")\n",
        "    if llm_config_shared_path.exists():\n",
        "        shutil.copy(llm_config_shared_path, llm_config_dst_path)\n",
        "    else:\n",
        "        download_file(url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/llm_config.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "611cc777-d5bc-4c7b-92e4-a4befa13b2ce",
      "metadata": {
        "id": "611cc777-d5bc-4c7b-92e4-a4befa13b2ce"
      },
      "source": [
        "## Select model for inference\n",
        "[back to top ⬆️](#Table-of-contents:)\n",
        "\n",
        "The tutorial supports different models, you can select one from the provided options to compare the quality of open source solutions.\n",
        ">**Note**: conversion of some models can require additional actions from user side and at least 64GB RAM for conversion.\n",
        "\n",
        "NuExtract model has several versions:\n",
        "\n",
        "* **NuExtract-tiny** - This is a version of [Qwen1.5-0.5](https://huggingface.co/Qwen/Qwen1.5-0.5B) model with 0.5 billion parameters. More details about the model can be found in [model card](https://huggingface.co/numind/NuExtract-tiny).\n",
        "* **NuExtract** - This is a version of [phi-3-mini](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct) model with 3.8 billion parameters. More details about the model can be found in [model card](https://huggingface.co/numind/NuExtract).\n",
        "* **NuExtract-large** - This is a version of [phi-3-small](https://huggingface.co/microsoft/Phi-3-small-8k-instruct) model with 7 billion parameters. More details about the model can be found in [model card](https://huggingface.co/numind/NuExtract-large).\n",
        "\n",
        "All NuExtract models are fine-tuned on a private high-quality synthetic dataset for information extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "27b42290-a9b5-4453-9a4c-ffa44bbd966d",
      "metadata": {
        "id": "27b42290-a9b5-4453-9a4c-ffa44bbd966d",
        "outputId": "7d1f84f6-94f1-4654-fcc4-7b0ce02c9ad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "bcd17f1963934a8b851199973c4b84d5",
            "43c9d79efcfb44e19b4f067270f88fec",
            "b2572b949ae447a49c6462cc79b33a3f",
            "e5bdce5b11fd44f495dafffc3fc20f17",
            "2abb92a975a54b4b9464bfe5c585648b",
            "80df3a0a57af484580385e3dcb70f634",
            "db5db6c07c9d4622a4215cc5ec3b4e0a",
            "cc6f8148e6a044d38a0c4258b7ca27da",
            "7142706902b94e10b9d07a5747569e04",
            "96f8a509535148ebaa2249050ba150d2",
            "7c501fbb2ccb45bebe0bfa58b822bdbd",
            "30c9ddb2b4c84427860be4b0e14e45bf",
            "afc211f2fcaf4de086ff96412a1c9631",
            "0e372842352e48c997a85cdee8fe5ab2",
            "1fe5e15be2f34a77aef29316dfae1478",
            "43ba64eca2de49c3bef8ead5d63246ec",
            "12cb1d1ed7f04a46a6aeac7f0df3a227",
            "207ea887d122414f816ceecd763e1b6c"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Box(children=(Box(children=(Label(value='Model:'), Dropdown(options={'NuExtract_tiny': {'model_id': 'numind/Nu…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcd17f1963934a8b851199973c4b84d5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from llm_config import get_llm_selection_widget\n",
        "\n",
        "models = {\n",
        "    \"NuExtract_tiny\": {\"model_id\": \"numind/NuExtract-tiny\"},\n",
        "    \"NuExtract\": {\"model_id\": \"numind/NuExtract\"},\n",
        "    \"NuExtract_large\": {\"model_id\": \"numind/NuExtract-large\"},\n",
        "}\n",
        "\n",
        "form, _, model_dropdown, compression_dropdown, _ = get_llm_selection_widget(languages=None, models=models, show_preconverted_checkbox=False)\n",
        "\n",
        "form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "37e9634f-4fc7-4d9c-9ade-b3e8684a0828",
      "metadata": {
        "id": "37e9634f-4fc7-4d9c-9ade-b3e8684a0828",
        "outputId": "78d6e507-8927-44d4-ba54-dcae561c17d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected model NuExtract_tiny with INT4 compression\n"
          ]
        }
      ],
      "source": [
        "model_name = model_dropdown.label\n",
        "model_config = model_dropdown.value\n",
        "print(f\"Selected model {model_name} with {compression_dropdown.value} compression\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3df73379-bccc-41b1-9c94-c3040819805b",
      "metadata": {
        "id": "3df73379-bccc-41b1-9c94-c3040819805b"
      },
      "source": [
        "## Select device for inference and model variant\n",
        "[back to top ⬆️](#Table-of-contents:)\n",
        "\n",
        ">**Note**: There may be no speedup for INT4/INT8 compressed models on dGPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d2d7bf5b-8a05-4c3b-a36b-631af5c197e9",
      "metadata": {
        "id": "d2d7bf5b-8a05-4c3b-a36b-631af5c197e9",
        "outputId": "bfb08697-878b-431a-e38e-91a11d0cb75a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "64231c181a744df9a28b7de854b514f4",
            "e3e576eee9b942f3ba3e377ec95ac6b8",
            "1331fccd14174afca332771b6afc7324"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Device:', options=('CPU', 'AUTO'), value='CPU')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64231c181a744df9a28b7de854b514f4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from notebook_utils import device_widget\n",
        "\n",
        "device = device_widget(default=\"CPU\", exclude=[\"NPU\"])\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf13f6c3-6671-408e-ae0e-aaa3d8a6eaac",
      "metadata": {
        "id": "bf13f6c3-6671-408e-ae0e-aaa3d8a6eaac"
      },
      "source": [
        "## Create a structure extraction inference pipeline\n",
        "[back to top ⬆️](#Table-of-contents:)\n",
        "\n",
        "Firstly we will prepare input prompt for NuExtract model by introducing `prepare_input()` function. This function combines the main text, a JSON schema and optional examples into a single string that adheres to model's specific input requirements.\n",
        "\n",
        "`prepare_input()` function accepts the following parameters:\n",
        "1. `text`: This is the primary text from which you want to extract information.\n",
        "2. `schema`: A JSON schema string that defines the structure of the information you want to extract. This acts as a template, guiding NuExtract model on what data to look for and how to format the output.\n",
        "3. `examples`: An optional list of example strings. These can be used to provide the model with sample extractions, potentially improving accuracy for complex or ambiguous cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "14d72874",
      "metadata": {
        "id": "14d72874"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def prepare_input(text: str, schema: str, examples: List[str] = [\"\", \"\", \"\"]) -> str:\n",
        "    schema = json.dumps(json.loads(schema), indent=4)\n",
        "    input_llm = \"<|input|>\\n### Template:\\n\" + schema + \"\\n\"\n",
        "    for example in examples:\n",
        "        if example != \"\":\n",
        "            input_llm += \"### Example:\\n\" + json.dumps(json.loads(example), indent=4) + \"\\n\"\n",
        "\n",
        "    input_llm += \"### Text:\\n\" + text + \"\\n<|output|>\\n\"\n",
        "    return input_llm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d41b78dd",
      "metadata": {
        "id": "d41b78dd"
      },
      "source": [
        "To simplify user experience we will use [OpenVINO Generate API](https://github.com/openvinotoolkit/openvino.genai/blob/master/src/README.md).\n",
        "We will create pipeline with `LLMPipeline`. `LLMPipeline` is the main object used for decoding. You can construct it straight away from the folder with the converted model. It will automatically load the `main model`, `tokenizer`, `detokenizer` and default `generation configuration`.\n",
        "After that we will configure parameters for decoding. We can get default config with `get_generation_config()`, setup parameters and apply the updated version with `set_generation_config(config)` or put config directly to `generate()`. It's also possible to specify the needed options just as inputs in the `generate()` method, as shown below.\n",
        "Then we just run `generate` method and get the output in text format. We do not need to encode input prompt according to model expected template or write post-processing code for logits decoder, it will be done easily with LLMPipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f1f295d4",
      "metadata": {
        "id": "f1f295d4"
      },
      "outputs": [],
      "source": [
        "import openvino_genai as ov_genai\n",
        "\n",
        "pipe = ov_genai.LLMPipeline(model_dir.as_posix(), device.value)\n",
        "\n",
        "\n",
        "def run_structure_extraction(text: str, schema: str) -> str:\n",
        "    input = prepare_input(text, schema)\n",
        "    return pipe.generate(input, max_new_tokens=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4820307d",
      "metadata": {
        "id": "4820307d"
      },
      "source": [
        "To run structure extraction inference pipeline we need to provide example text for data extraction and define output structure in a JSON schema format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "38925684",
      "metadata": {
        "id": "38925684",
        "outputId": "77ecb668-543f-47a3-c54c-abffed041f6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Model\": {\n",
            "        \"Name\": \"Mistral 7B\",\n",
            "        \"Number of parameters\": \"7-billion\",\n",
            "        \"Number of max token\": \"\",\n",
            "        \"Architecture\": [\n",
            "            \"grouped-query attention\",\n",
            "            \"sliding window attention\"\n",
            "        ]\n",
            "    },\n",
            "    \"Usage\": {\n",
            "        \"Use case\": [\n",
            "            \"reasoning\",\n",
            "            \"mathematics\",\n",
            "            \"code generation\"\n",
            "        ],\n",
            "        \"Licence\": \"Apache 2.0\"\n",
            "    }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"We introduce Mistral 7B, a 7-billion-parameter language model engineered for\n",
        "superior performance and efficiency. Mistral 7B outperforms the best open 13B\n",
        "model (Llama 2) across all evaluated benchmarks, and the best released 34B\n",
        "model (Llama 1) in reasoning, mathematics, and code generation. Our model\n",
        "leverages grouped-query attention (GQA) for faster inference, coupled with sliding\n",
        "window attention (SWA) to effectively handle sequences of arbitrary length with a\n",
        "reduced inference cost. We also provide a model fine-tuned to follow instructions,\n",
        "Mistral 7B - Instruct, that surpasses Llama 2 13B - chat model both on human and\n",
        "automated benchmarks. Our models are released under the Apache 2.0 license.\n",
        "Code: https://github.com/mistralai/mistral-src\n",
        "Webpage: https://mistral.ai/news/announcing-mistral-7b/\"\"\"\n",
        "\n",
        "schema = \"\"\"{\n",
        "    \"Model\": {\n",
        "        \"Name\": \"\",\n",
        "        \"Number of parameters\": \"\",\n",
        "        \"Number of max token\": \"\",\n",
        "        \"Architecture\": []\n",
        "    },\n",
        "    \"Usage\": {\n",
        "        \"Use case\": [],\n",
        "        \"Licence\": \"\"\n",
        "    }\n",
        "}\"\"\"\n",
        "\n",
        "output = run_structure_extraction(text, schema)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31ebb167-0e55-4271-aedd-13814c2356d2",
      "metadata": {
        "id": "31ebb167-0e55-4271-aedd-13814c2356d2"
      },
      "source": [
        "## Run interactive structure extraction demo with Gradio\n",
        "[back to top ⬆️](#Table-of-contents:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9f222d02-847a-490f-8d66-02608a53259b",
      "metadata": {
        "scrolled": true,
        "id": "9f222d02-847a-490f-8d66-02608a53259b",
        "outputId": "d6287f87-175b-429b-8b0f-293ca4579eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0b81c07a84c46fbc43.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0b81c07a84c46fbc43.gradio.live\" width=\"100%\" height=\"800\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if not Path(\"gradio_helper.py\").exists():\n",
        "    r = requests.get(\n",
        "        url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/nuextract-structure-extraction/gradio_helper.py\"\n",
        "    )\n",
        "    open(\"gradio_helper.py\", \"w\").write(r.text)\n",
        "\n",
        "from gradio_helper import make_demo\n",
        "\n",
        "demo = make_demo(fn=run_structure_extraction)\n",
        "\n",
        "try:\n",
        "    demo.launch(height=800)\n",
        "except Exception:\n",
        "    demo.launch(share=True, height=800)\n",
        "# If you are launching remotely, specify server_name and server_port\n",
        "# EXAMPLE: `demo.launch(server_name='your server name', server_port='server port in int')`\n",
        "# To learn more please refer to the Gradio docs: https://gradio.app/docs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "405f3117",
      "metadata": {
        "id": "405f3117",
        "outputId": "7e3b92c7-06b7-4267-8f55-ff24c7a4d8c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ],
      "source": [
        "# Uncomment and run this cell for stopping gradio interface\n",
        "demo.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "openvino_notebooks": {
      "imageUrl": "https://github.com/user-attachments/assets/70dd93cc-da36-4c53-8891-78c0f9a41f20",
      "tags": {
        "categories": [
          "Model Demos",
          "AI Trends"
        ],
        "libraries": [],
        "other": [
          "LLM"
        ],
        "tasks": [
          "Text Generation"
        ]
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bcd17f1963934a8b851199973c4b84d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43c9d79efcfb44e19b4f067270f88fec",
              "IPY_MODEL_b2572b949ae447a49c6462cc79b33a3f"
            ],
            "layout": "IPY_MODEL_e5bdce5b11fd44f495dafffc3fc20f17"
          }
        },
        "43c9d79efcfb44e19b4f067270f88fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2abb92a975a54b4b9464bfe5c585648b",
              "IPY_MODEL_80df3a0a57af484580385e3dcb70f634"
            ],
            "layout": "IPY_MODEL_db5db6c07c9d4622a4215cc5ec3b4e0a"
          }
        },
        "b2572b949ae447a49c6462cc79b33a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc6f8148e6a044d38a0c4258b7ca27da",
              "IPY_MODEL_7142706902b94e10b9d07a5747569e04"
            ],
            "layout": "IPY_MODEL_96f8a509535148ebaa2249050ba150d2"
          }
        },
        "e5bdce5b11fd44f495dafffc3fc20f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "solid 1px",
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "1%",
            "right": null,
            "top": null,
            "visibility": null,
            "width": "30%"
          }
        },
        "2abb92a975a54b4b9464bfe5c585648b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c501fbb2ccb45bebe0bfa58b822bdbd",
            "placeholder": "​",
            "style": "IPY_MODEL_30c9ddb2b4c84427860be4b0e14e45bf",
            "value": "Model:"
          }
        },
        "80df3a0a57af484580385e3dcb70f634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "NuExtract_tiny",
              "NuExtract",
              "NuExtract_large"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_afc211f2fcaf4de086ff96412a1c9631",
            "style": "IPY_MODEL_0e372842352e48c997a85cdee8fe5ab2"
          }
        },
        "db5db6c07c9d4622a4215cc5ec3b4e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc6f8148e6a044d38a0c4258b7ca27da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fe5e15be2f34a77aef29316dfae1478",
            "placeholder": "​",
            "style": "IPY_MODEL_43ba64eca2de49c3bef8ead5d63246ec",
            "value": "Compression:"
          }
        },
        "7142706902b94e10b9d07a5747569e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "INT4",
              "INT4-AWQ",
              "INT8",
              "FP16"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_12cb1d1ed7f04a46a6aeac7f0df3a227",
            "style": "IPY_MODEL_207ea887d122414f816ceecd763e1b6c"
          }
        },
        "96f8a509535148ebaa2249050ba150d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c501fbb2ccb45bebe0bfa58b822bdbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c9ddb2b4c84427860be4b0e14e45bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afc211f2fcaf4de086ff96412a1c9631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e372842352e48c997a85cdee8fe5ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fe5e15be2f34a77aef29316dfae1478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43ba64eca2de49c3bef8ead5d63246ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12cb1d1ed7f04a46a6aeac7f0df3a227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "207ea887d122414f816ceecd763e1b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64231c181a744df9a28b7de854b514f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "CPU",
              "AUTO"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Device:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_e3e576eee9b942f3ba3e377ec95ac6b8",
            "style": "IPY_MODEL_1331fccd14174afca332771b6afc7324"
          }
        },
        "e3e576eee9b942f3ba3e377ec95ac6b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1331fccd14174afca332771b6afc7324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}